# üê± HelloKitty ‚Äì Projet Robot Chat
<img width="810" height="1080" alt="image" src="https://github.com/user-attachments/assets/7b001b46-020f-4a15-b75d-87ee0aa59870" />


### **Les contributeurs :**
-BENJEMAA Aymen
-SOLTANI Ezer
-ROUABAH Serine

## üìö Table des mati√®res

1. [üìú Pr√©sentation g√©n√©rale](#-pr√©sentation-g√©n√©rale)
2. [üìê Architecture mat√©rielle](#-architecture-mat√©rielle)
   - [üîå Sch√©ma syst√®me](#-sch√©ma-syst√®me)
   - [üìå Pinout STM32](#-pinout-stm32)
   - [üõ†Ô∏è PCB et design √©lectronique](#-pcb-et-design-√©lectronique)
3. [üß© Architecture logicielle](#-architecture-logicielle)
   - [üß± Couches logicielles](#-couches-logicielles)
   - [üïí Fonctionnement des t√¢ches FreeRTOS](#-fonctionnement-des-t√¢ches-freertos)
   - [üîÑ Synchronisation et priorit√©s](#-synchronisation-et-priorit√©s)
4. [‚öôÔ∏è Drivers et HAL](#-drivers-et-hal)
5. [üéØ Strat√©gie comportementale](#-strat√©gie-comportementale)
6. [üìä Tests et validation](#-tests-et-validation)
7. [üîß R√©sultats et perspectives](#-r√©sultats-et-perspectives)

## Pr√©sentation g√©n√©rale

HelloKitty est un robot mobile autonome con√ßu pour √©voluer sur une surface plane sans bordure, dans un jeu de poursuite entre plusieurs robots. Le projet s‚Äôinscrit dans le cadre du module Syst√®mes √âlectroniques Avanc√©s de l‚ÄôENSEA, et vise √† couvrir l‚Äôensemble du cycle de d√©veloppement embarqu√©‚ÄØ: de la conception du PCB √† l‚Äôimpl√©mentation logicielle temps r√©el, en passant par la strat√©gie comportementale.

Le robot est capable de d√©tecter les bords, d‚Äô√©viter les chutes, de rep√©rer d‚Äôautres robots, et de changer de r√¥le (chat ‚Üî souris) en fonction des interactions physiques ou visuelles. Le projet met en ≈ìuvre des capteurs vari√©s, une architecture logicielle modulaire, et une gestion fine des t√¢ches concurrentes via FreeRTOS.

## **Architecture**  
### **Sch√©ma architectural**  

<img width="927" height="693" alt="schema_projet" src="https://github.com/user-attachments/assets/1b3bfaf2-3be3-44c0-845a-d9920e9071d3" />

#  Architecture du syst√®me embarqu√© STM32G431CBU6

Ce projet repose sur un microcontr√¥leur **STM32G431CBU6**, int√©grant divers capteurs, modules de communication, moteurs et interfaces utilisateur pour cr√©er un syst√®me autonome capable de capter, traiter et agir dans un environnement physique.

##  Microcontr√¥leur central
- **STM32G431CBU6** : c≈ìur du syst√®me, g√®re les communications, le traitement des donn√©es et le contr√¥le des p√©riph√©riques.

## Alimentation
- **Batterie NiMH 7.2V 1.3Ah** : source principale d‚Äô√©nergie.
- **R√©gulateurs de tension** :
  - **MP1475DJ-LF-P** : convertit la tension en **5V**.
  - **BU33SD5WG-TR** : convertit en **3.3V** pour les composants sensibles.

## Capteurs et modules
- **4 capteurs TOF (Time-of-Flight)** : connect√©s via **I2C**, pour mesurer les distances.
- **Acc√©l√©rom√®tre ADXL343** : connect√© en **I2C**, pour d√©tecter les mouvements.
- **Module Bluetooth** : communication sans fil via **UART**.
- **Lidar YDLIDAR X2** : capteur de t√©l√©m√©trie, connect√© en **UART**.

## Horloge et programmation
- **Quartz 16MHz** : fournit une horloge stable au microcontr√¥leur.
- **STLink SWD** : interface de programmation et d√©bogage.
- **Hclk** : 170Mhz.

## Moteurs et contr√¥le
- **2 pilotes de moteur ZXBM5210** : re√ßoivent des signaux **PWM** pour contr√¥ler les moteurs gauche et droit.
- **Moteurs avec encodeurs** : permettent un retour de position et de vitesse.

## üñ±Ô∏è Interface utilisateur
- **LED** : sortie **GPIO**, pour signalisation.
- **Bouton utilisateur** : entr√©e **GPIO**, pour interaction manuelle.
- **Bouton reset** : pour red√©marrer le syst√®me.

## üîå Connexions color√©es
- **Rouge** : lignes d‚Äôalimentation **5V**
- **Orange** : lignes **3.3V**
- **Violet** : **I2C**
- **Bleu** : **UART**
- **Vert** : **GPIO**
- **Noir** : **PWM**

---

Ce sch√©ma illustre l‚Äôinterconnexion des modules pour un syst√®me embarqu√© intelligent et r√©actif.

## Fonctionnement interne du robot

Le robot ne se contente pas d‚Äôex√©cuter des actions simples : son microcontr√¥leur coordonne en continu l‚Äôensemble des capteurs, moteurs et modules pour produire un comportement coh√©rent et r√©actif. Cette section d√©crit la logique interne qui permet au syst√®me de fonctionner de mani√®re autonome.

### Organisation logicielle
Le logiciel embarqu√© est structur√© en plusieurs t√¢ches ind√©pendantes.  
Chaque t√¢che s‚Äôoccupe d‚Äôun domaine pr√©cis : analyse des distances, lecture des chocs, gestion des moteurs ou encore surveillance de l‚Äôenvironnement.  
Cette organisation √©vite qu‚Äôune op√©ration bloque les autres et garantit une r√©activit√© constante.

### Syst√®me de d√©cision
Le robot suit une hi√©rarchie de priorit√©s pour r√©agir correctement aux √©v√©nements :
- **S√©curit√© imm√©diate** : arr√™t ou retrait en cas de danger (vide, obstacle trop proche, choc).
- **√âvitement** : choix de la direction la plus d√©gag√©e gr√¢ce aux donn√©es du LiDAR.
- **D√©placement normal** : progression ou patrouille lorsque l‚Äôenvironnement est stable.

Cette logique emp√™che les comportements incoh√©rents et permet des r√©actions rapides.

### Gestion dynamique des moteurs
Les moteurs sont ajust√©s en permanence selon la situation :
- correction de trajectoire,
- adaptation de la vitesse,
- compensation en cas de r√©sistance ou de choc.

Le microcontr√¥leur calcule ces ajustements en temps r√©el, tandis que les drivers appliquent les consignes via PWM.

### Fusion des capteurs
Les informations issues des diff√©rents capteurs sont combin√©es pour obtenir une vision plus fiable de l‚Äôenvironnement :
- les ToF surveillent les bords,
- le LiDAR analyse l‚Äôespace autour du robot,
- l‚Äôacc√©l√©rom√®tre d√©tecte les impacts ou blocages.

Cette fusion permet d‚Äôanticiper les risques et d‚Äôadapter le comportement du robot de mani√®re fluide.

### √âtats internes
Le robot fonctionne comme une machine √† √©tats, chacun correspondant √† un comportement pr√©cis :
- exploration,
- √©vitement,
- collision d√©tect√©e,
- danger de chute,
- blocage,
- repos.

Chaque √©tat d√©finit les actions √† effectuer et les conditions pour passer √† un autre √©tat.

### Indicateurs lumineux
Les LEDs servent de retour visuel pour comprendre l‚Äô√©tat du robot :
- clignotement rapide : alerte,
- clignotement lent : attente,
- lumi√®re fixe : fonctionnement normal.

Elles permettent de diagnostiquer rapidement le comportement du robot sans acc√©der au code.

### Synchronisation des communications
Les diff√©rents protocoles (UART, SPI, I2C) fonctionnent en parall√®le.  
Pour √©viter les conflits, les √©changes sont cadenc√©s et certaines lectures sont prioritaires.  
Les interruptions mat√©rielles assurent la prise en charge imm√©diate des √©v√©nements critiques.

---

Cette architecture logicielle permet au robot d‚Äô√™tre autonome, r√©actif et capable de s‚Äôadapter en temps r√©el √† son environnement.


##  Partie Hardware

Cette section d√©crit l‚Äôarchitecture mat√©rielle du robot, ses composants √©lectroniques, et les sch√©mas associ√©s.
<img width="983" height="564" alt="image" src="https://github.com/user-attachments/assets/481b72ed-1033-43fa-afc0-7f35f21c6596" />


### üîå Sch√©ma global du syst√®me
Le syst√®me repose sur un microcontr√¥leur **STM32G431CBU6** qui coordonne les capteurs, les moteurs, les r√©gulateurs et les interfaces utilisateur.


---

### ‚öôÔ∏è Microcontr√¥leur et interfaces
Le microcontr√¥leur est au c≈ìur du syst√®me. Il est connect√© :
- aux moteurs via des signaux **PWM** et des entr√©es d‚Äôencodeurs,
- aux capteurs via **UART**, **I2C**, et **GPIO**,
- √† un **STLink/SWD** pour la programmation et le d√©bogage.

<img width="1078" height="742" alt="image" src="https://github.com/user-attachments/assets/20eed7e6-8ec8-43f0-a155-ee942acf7542" />


---

### üîã Alimentation et r√©gulation
Le robot est aliment√© par une batterie **NiMH 7.2V**, r√©gul√©e en deux tensions :
- **5V** via le r√©gulateur **MP1475DJ-LF-P**,
- **3.3V** via le r√©gulateur **BU33SD5WG-TR**.

Ces tensions alimentent les moteurs, le microcontr√¥leur et les capteurs sensibles.

<img width="1013" height="592" alt="image" src="https://github.com/user-attachments/assets/fa8be56d-729b-44cd-a620-70aa3347fee2" />


---

### ü¶æ Pilotes de moteurs
Chaque moteur est contr√¥l√© par un circuit **ZXBM5210-SP**, avec :
- deux entr√©es **PWM** pour la vitesse et la direction,
- deux sorties vers le moteur (Motor+ / Motor‚àí),
- des entr√©es d‚Äôencodeurs pour le retour de position.

Chaque moteur dispose de son propre driver et de ses propres signaux.

<img width="570" height="256" alt="image" src="https://github.com/user-attachments/assets/a448f5a5-3051-4683-b620-6901f1f0ada8" />

---

### üì° Capteurs
Le syst√®me int√®gre :
- **4 capteurs TOF** pour la d√©tection de bordure,
- **1 acc√©l√©rom√®tre ADXL343** pour les chocs et mouvements,
- **1 LiDAR YDLIDAR X2** pour la cartographie et l‚Äô√©vitement,
- **1 module Bluetooth** pour la communication sans fil.

Tous ces capteurs sont connect√©s au microcontr√¥leur via **I2C**, **SPI**, **UART** ou **GPIO**.
<img width="1062" height="625" alt="image" src="https://github.com/user-attachments/assets/a634e98e-761b-432a-a299-bae5318e2d9d" />

---

### üñ±Ô∏è Interface utilisateur
Le robot dispose :
- de **LEDs** pour indiquer son √©tat (obstacle, marche, pause‚Ä¶),
- d‚Äôun **bouton utilisateur** pour les interactions manuelles,
- d‚Äôun **bouton reset** pour red√©marrer le syst√®me.
##im

---

### üß© Organisation des fichiers KiCad
Les sch√©mas sont r√©partis en plusieurs fichiers :
- `pucontrolleur.kicad.sch` : microcontr√¥leur et interfaces
- `moteur1.kicad.sch` / `moteur2.kicad.sch` : circuits moteurs
- `regulateurs.kicad.sch` : alimentation
- `capteurs.kicad.sch` : capteurs et communication

---

Cette architecture mat√©rielle permet au robot d‚Äô√™tre autonome, r√©actif et modulaire. Chaque composant est interconnect√© pour assurer un fonctionnement fluide et s√©curis√©.




# üß© Architecture logicielle

Cette section d√©taille l'organisation logicielle du robot, son syst√®me d'exploitation temps r√©el (FreeRTOS), les drivers pour les p√©riph√©riques mat√©riels, et la logique comportementale qui r√©git ses actions.

## üß± Couches logicielles

Le logiciel embarqu√© est construit sur une architecture multicouche modulaire pour garantir la maintenabilit√©, la r√©activit√© et la fiabilit√©. Le syst√®me d'exploitation temps r√©el **FreeRTOS** est au c≈ìur de cette architecture, orchestrant plusieurs t√¢ches concurrentes qui g√®rent des aspects sp√©cifiques du robot.

Les principales couches logicielles sont :
1.  **Couche d'Application (Strat√©gie) :** La logique de haut niveau qui prend des d√©cisions bas√©es sur les donn√©es des capteurs et l'√©tat actuel du robot.
2.  **Couche de Service (T√¢ches FreeRTOS) :** Des t√¢ches ind√©pendantes qui g√®rent des fonctionnalit√©s sp√©cifiques comme la communication, la gestion des moteurs ou la surveillance des capteurs.
3.  **Couche d'Abstraction Mat√©rielle (HAL) :** Les drivers et les biblioth√®ques HAL de STMicroelectronics qui fournissent une interface standardis√©e pour interagir avec le mat√©riel du microcontr√¥leur.
4.  **Couche Mat√©rielle :** Le microcontr√¥leur STM32G431CBU6 et ses p√©riph√©riques.

## üïí Fonctionnement des t√¢ches FreeRTOS

Ce fichier est le c≈ìur de l'application temps r√©el. Il initialise les t√¢ches FreeRTOS, les mutex et autres objets de synchronisation.

| T√¢che | Priorit√© | Description |
| :--- | :--- | :--- |
| `vControlTask` | 4 (Haute) | Contr√¥le les moteurs via PID et ex√©cute la strat√©gie comportementale. |
| `vSafetyTask` | 3 (Moyenne-Haute) | Surveille les capteurs TOF pour √©viter les chutes. |
| `vLidarTask` | 2 (Moyenne) | Traite les donn√©es du Lidar pour la d√©tection d'obstacles. |
| `vImuTask` | 1 (Basse) | Lit l'acc√©l√©rom√®tre pour d√©tecter les chocs. |

### T√¢ches des Capteurs et de la S√©curit√©

-   **`vSafetyTask`**: Cette t√¢che lit les capteurs TOF pour d√©tecter le vide. Si un risque de chute est d√©tect√©, elle prend le contr√¥le des moteurs (`g_safety_override`) pour effectuer une man≈ìuvre d'√©vitement.
-   **`vLidarTask`**: Elle traite en continu le flux de donn√©es du Lidar pour d√©tecter et suivre les objets environnants. L'objet le plus proche est stock√© pour √™tre utilis√© par la t√¢che de strat√©gie.
-   **`vImuTask`**: Elle surveille l'acc√©l√©rom√®tre pour d√©tecter les chocs. Un choc d√©clenche un changement de r√¥le (Chat ‚Üî Souris).

```c
// Extrait de vSafetyTask
void vSafetyTask(void *pvParameters)
{
  for(;;) {
      // Lecture des capteurs TOF
      if (xSemaphoreTake(xI2C1Mutex, portMAX_DELAY) == pdTRUE) {
          TOF_Read_All(dist);
          xSemaphoreGive(xI2C1Mutex);
      }

      // Si un vide est d√©tect√© en avant
      if (dist[0] > 200 || dist[1] > 200) {
          g_safety_override = 1; // Prend le contr√¥le
          // ... S√©quence de recul et rotation ...
          g_safety_override = 0; // Rend le contr√¥le
      }
      vTaskDelay(pdMS_TO_TICKS(10));
  }
}
```

### T√¢che de Contr√¥le Moteur (`vControlTask`)

C'est la t√¢che la plus complexe. Elle est responsable de :
1.  **Mettre √† jour la vitesse** mesur√©e des moteurs √† partir des encodeurs.
2.  **Ex√©cuter la strat√©gie** (`Strategy_Update()`) pour obtenir les vitesses cibles (lin√©aire et angulaire).
3.  **Calculer les vitesses cibles** pour chaque roue.
4.  **Ex√©cuter les boucles d'asservissement PID** pour chaque moteur.
5.  **Appliquer la commande PWM** aux drivers des moteurs.

```c
// Extrait de vControlTask
void vControlTask(void *pvParameters)
{
    // Initialisation des PIDs et de l'odom√©trie
    PID_Init(...);

    for(;;)
    {
        // 1. Mesure de la vitesse
        Motor_UpdateSpeed(&hMotor1, dt);
        Motor_UpdateSpeed(&hMotor2, dt);

        if (g_safety_override == 0) {
            // 2. Ex√©cution de la strat√©gie
            Strategy_Update();

            // 3. Calcul des vitesses des roues
            float target_rad_L = (v_lin - (v_ang * half_track)) / radius;
            float target_rad_R = (v_lin + (v_ang * half_track)) / radius;

            // 4. Calcul de la commande PID
            float pwm_L = PID_Compute(&pid_vel_left,  target_rad_L, speed_L);
            float pwm_R = PID_Compute(&pid_vel_right, target_rad_R, speed_R);

            // 5. Application de la commande
            Motor_SetSpeed(&hMotor2, -pwm_L);
            Motor_SetSpeed(&hMotor1, pwm_R);
        }
        vTaskDelayUntil(&xLastWakeTime, pdMS_TO_TICKS(10));
    }
}
```

## üîÑ Synchronisation et priorit√©s

La gestion des t√¢ches concurrentes est cruciale pour la stabilit√© du syst√®me.

### Priorit√©s des T√¢ches
Les priorit√©s sont attribu√©es en fonction de la criticit√© de chaque t√¢che :
1.  **`vControlTask` (Priorit√© 4 - Haute) :** Le contr√¥le des moteurs doit √™tre le plus r√©actif possible pour garantir la stabilit√© et l'asservissement.
2.  **`vSafetyTask` (Priorit√© 3) :** La d√©tection de chute est une fonction de s√©curit√© critique qui doit pouvoir interrompre le comportement normal du robot.
3.  **`vLidarTask` (Priorit√© 2) :** Le traitement des donn√©es du Lidar est important pour la navigation, mais moins critique que la s√©curit√© imm√©diate.
4.  **`vImuTask` (Priorit√© 1 - Basse) :** La d√©tection de choc est un √©v√©nement moins fr√©quent et moins critique que les autres.

### M√©canismes de Synchronisation
-   **Mutex (Semaphores Mutex) :** Des mutex sont utilis√©s pour prot√©ger les ressources partag√©es contre les acc√®s concurrents.
    -   `xI2C1Mutex`: Prot√®ge le bus I2C1, utilis√© par l'IMU et les capteurs TOF.
    -   `xUARTMutex`: Prot√®ge les acc√®s √† l'UART, notamment pour l'envoi de logs de d√©bogage.

```c
// extrait de app_freertos.c
void MX_FREERTOS_Init(void) {
  /* Create Mutexes */
  xI2C1Mutex = xSemaphoreCreateMutex();
  xUARTMutex = xSemaphoreCreateMutex();
  // ...
}
```

## ‚öôÔ∏è Drivers et HAL

Cette section d√©crit l'initialisation des p√©riph√©riques et des drivers. Le fichier `main.c` est le point de d√©part pour l'initialisation de bas niveau.

```c
// extrait de main.c
int main(void)
{
  // ...
  // Initialisation des p√©riph√©riques
  MX_GPIO_Init();
  MX_DMA_Init();
  MX_I2C1_Init();
  MX_USART2_UART_Init(); // Lidar
  MX_USART3_UART_Init(); // Bluetooth
  MX_USART1_UART_Init(); // Debug
  MX_TIM2_Init();      // Encoder Moteur Droit
  MX_TIM3_Init();      // PWM Moteurs
  MX_TIM4_Init();      // Encoder Moteur Gauche

  // Initialisation des drivers sp√©cifiques
  TOF_Init_All();
  // ...
  MX_FREERTOS_Init();
  vTaskStartScheduler();
  // ...
}
```

## üéØ Strat√©gie comportementale

Le fichier `strategy.c` impl√©mente la logique de haut niveau du robot. Il utilise une machine √† √©tats pour d√©cider du comportement √† adopter en fonction du r√¥le (Chat ou Souris) et des informations des capteurs.

### R√¥les et √âtats

-   **R√¥les :** `ROLE_CHAT` (attaquer) ou `ROLE_SOURIS` (fuir). Le r√¥le change lors d'un choc (`Strategy_ToggleRole`).
-   **√âtats :**
    -   `STATE_SEARCH`: Le robot tourne sur lui-m√™me √† la recherche d'une cible.
    -   `STATE_ATTACK`: Le robot (en mode Chat) se dirige vers la cible.
    -   `STATE_FLEE`: Le robot (en mode Souris) fuit la cible.
    -   `STATE_IDLE`: Le robot est √† l'arr√™t.

### Logique de la `Strategy_Update`

Cette fonction est appel√©e p√©riodiquement par la `vControlTask`.

```c
// Extrait de strategy.c
void Strategy_Update(void) {
    LidarTarget_t target = ydlidar_get_target();

    switch (current_state) {
        case STATE_SEARCH:
            // Le robot tourne sur lui-m√™me
            target_speed_lin_x = 0.0f;
            target_speed_ang_z = SEARCH_ROT_SPEED;

            // Si une cible est trouv√©e, changer d'√©tat
            if (target.is_valid) {
                current_state = (current_role == ROLE_CHAT) ? STATE_ATTACK : STATE_FLEE;
            }
            break;
        // ...
    }
}
```

### D√©tail des √âtats de la Strat√©gie

-   #### `STATE_IDLE`
    -   **Objectif :** Mettre le robot en √©tat de pause.
    -   **Actions :**
        -   `target_speed_lin_x` = 0.0f
        -   `target_speed_ang_z` = 0.0f
    -   **Entr√©e :** Cet √©tat est g√©n√©ralement activ√© lorsque le robot est d√©sactiv√© via la commande `Strategy_SetEnabled(0)`.
    -   **Sortie :** Repasse √† `STATE_SEARCH` lorsque le robot est r√©activ√© (`Strategy_SetEnabled(1)`).

-   #### `STATE_SEARCH`
    -   **Objectif :** Trouver un autre robot dans l'environnement.
    -   **Actions :**
        -   Le robot effectue une rotation lente sur lui-m√™me (`target_speed_ang_z = SEARCH_ROT_SPEED`).
        -   La vitesse lin√©aire est nulle (`target_speed_lin_x = 0.0f`).
    -   **Entr√©e :** C'est l'√©tat par d√©faut au d√©marrage, ou apr√®s avoir perdu une cible.
    -   **Sortie :**
        -   Si une cible est d√©tect√©e par le Lidar (`target.is_valid`):
            -   Si le r√¥le est `ROLE_CHAT`, passe √† `STATE_ATTACK`.
            -   Si le r√¥le est `ROLE_SOURIS`, passe √† `STATE_FLEE`.

-   #### `STATE_ATTACK`
    -   **Objectif :** (Pour le Chat) Poursuivre et intercepter la Souris.
    -   **Actions :**
        -   Un contr√¥leur proportionnel simple est utilis√© pour s'aligner avec la cible. La vitesse de rotation (`target_speed_ang_z`) est proportionnelle √† l'erreur d'angle par rapport √† la cible.
        -   Si le robot est bien align√©, il avance vers la cible √† une vitesse quasi-constante (`ATTACK_LIN_SPEED`).
        -   La vitesse ralentit √† proximit√© de la cible pour un contact en douceur.
    -   **Entr√©e :** Depuis `STATE_SEARCH`, lorsque le robot est un `ROLE_CHAT` et qu'une cible est d√©tect√©e.
    -   **Sortie :**
        -   Si la cible est perdue (`!target.is_valid`), retourne √† `STATE_SEARCH`.
        -   Si le r√¥le change en `ROLE_SOURIS` (apr√®s un choc), la s√©curit√© dans le code force un retour √† `STATE_SEARCH`.

-   #### `STATE_FLEE`
    -   **Objectif :** (Pour la Souris) √âchapper au Chat.
    -   **Actions :**
        -   La logique est l'inverse de l'attaque : le robot calcule un angle oppos√© (180¬∞) √† la position du Chat.
        -   Il s'oriente dans cette direction de fuite.
        -   Une fois orient√©, il acc√©l√®re (`FLEE_LIN_SPEED`) pour s'√©loigner le plus rapidement possible.
    -   **Entr√©e :** Depuis `STATE_SEARCH`, lorsque le robot est une `ROLE_SOURIS` et qu'une menace est d√©tect√©e.
    -   **Sortie :**
        -   Si la menace dispara√Æt (`!target.is_valid`), retourne √† `STATE_SEARCH`.
        -   Si le r√¥le change en `ROLE_CHAT`, retourne √† `STATE_SEARCH`.

## üìä Tests et validation
### Communication USART via Module Bluetooth HC-05

La communication sans fil avec le module Bluetooth HC-05 est essentielle pour le d√©bogage en temps r√©el et la t√©l√©m√©trie.

-   **Utilisation :** Le module HC-05 est connect√© √† l'UART3 du microcontr√¥leur. Il est configur√© pour un d√©bit de 9600 bauds (ou autre, selon la configuration du module).
-   **Donn√©es Transmises :**
    -   **Messages de D√©bogage (`printf`) :** Toutes les sorties `printf` du syst√®me sont redirig√©es vers l'UART1 (pour la console s√©rie filaire) et vers l'UART3 (pour le Bluetooth). Cela permet de suivre le comportement du robot sans fil.
    -   **T√©l√©m√©trie :** Des donn√©es critiques comme l'√©tat actuel du robot, les distances des capteurs, les vitesses des moteurs, ou les coordonn√©es d'odom√©trie peuvent √™tre envoy√©es via Bluetooth √† une application externe (ex: un terminal s√©rie sur PC ou un smartphone).
-   **V√©rification :**
    1.  **Connexion :** Assurez-vous que le module HC-05 est correctement appair√© √† votre terminal Bluetooth (PC, smartphone). Le LED du module devrait passer de clignotement rapide √† lent/fixe une fois connect√©.
    2.  **Test `printf` :** Apr√®s le d√©marrage du robot, les messages "Starting System..." et "TOF Init Done." devraient appara√Ætre sur le terminal Bluetooth.
    3.  **Surveillance en Temps R√©el :** Des messages indiquant les changements d'√©tat de la strat√©gie (ATTACK, FLEE), les d√©tections de chocs, ou les alertes de s√©curit√© (VOID DETECTED) devraient √™tre visibles en temps r√©el.
    4.  **Envoi de Commandes (Optionnel) :** Si l'application int√®gre la r√©ception de commandes via Bluetooth, testez l'envoi de commandes simples (ex: "START", "STOP", "CHANGE_ROLE") depuis votre terminal pour v√©rifier la r√©activit√© du robot.

```c
// Extrait de main.c pour la redirection de printf
int __io_putchar(int ch)
{
	HAL_UART_Transmit(&huart1, (uint8_t*)&ch, 1, HAL_MAX_DELAY); // Debug filaire
	HAL_UART_Transmit(&huart3, (uint8_t*)&ch, 1, HAL_MAX_DELAY); // Bluetooth
	return ch;
}

// Extrait de app_freertos.c pour l'initialisation du HC-05
void MX_FREERTOS_Init(void) {
  // ...
  HC05_Init(); // Initialisation du driver Bluetooth
  // ...
}
```
<img width="1220" height="2712" alt="image" src="https://github.com/user-attachments/assets/a8628635-f0d2-4451-8770-b7ae8a8bb45b" />


## üîß R√©sultats et perspectives

Le projet illustre la mise en ≈ìuvre compl√®te d‚Äôun syst√®me embarqu√© autonome, combinant conception √©lectronique, programmation temps r√©el et strat√©gie comportementale. √Ä travers le d√©veloppement d‚Äôune carte √©lectronique d√©di√©e autour du STM32G431CBU6, l‚Äôint√©gration de capteurs vari√©s et l‚Äôutilisation de FreeRTOS, le robot est capable d‚Äôinteragir de mani√®re fiable et r√©active avec son environnement.

L‚Äôarchitecture logicielle modulaire, bas√©e sur des t√¢ches concurrentes hi√©rarchis√©es, garantit la s√©curit√© du robot tout en assurant un contr√¥le pr√©cis des moteurs et une prise de d√©cision fluide. La strat√©gie Chat / Souris, impl√©ment√©e sous forme de machine √† √©tats, d√©montre la capacit√© du syst√®me √† adapter dynamiquement son comportement en fonction des √©v√©nements d√©tect√©s (obstacles, chocs, pr√©sence d‚Äôun autre robot).

Les tests r√©alis√©s, notamment via la communication Bluetooth et les d√©monstrations en conditions r√©elles, valident la robustesse du syst√®me et la coh√©rence entre les choix mat√©riels et logiciels. Le robot fonctionne de mani√®re autonome, √©vite les chutes, d√©tecte son environnement et interagit avec d‚Äôautres robots conform√©ment aux objectifs du projet.

Ce projet constitue une base solide pour des am√©liorations futures, telles que l‚Äôint√©gration d‚Äôalgorithmes de navigation plus avanc√©s, l‚Äôoptimisation √©nerg√©tique ou l‚Äôextension vers des sc√©narios multi-robots plus complexes.


https://github.com/user-attachments/assets/d23f3977-9c8e-4610-84ae-4908d1821f06


